{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intensive-suspension",
   "metadata": {},
   "source": [
    "# 머신러닝을 이용한 뉴스 카테고리 분류 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-penetration",
   "metadata": {},
   "source": [
    "#### 초록\n",
    "***\n",
    "<span style=\"font-size:11pt; line-height:1.8;\">\n",
    "    &nbsp; &nbsp; 로이터 뉴스 데이터셋을 이용하여, (1) '고전적 머신러닝 모델과 딥러닝 모델의 성능 차이' (2) '단어사전 크기에 따른 모델의 성능 차이'를 확인 하였다. 로이터 뉴스 데이터셋은 '뉴스 본문'과 '본문에 해당하는 카테고리에 대한 값'이 한 쌍으로 학습 데이터 8,982개, 테스트 데이터 2,246개로 이루어져 있다. 데이터셋의 클래스 별 데이터 분포가 불균형 하다는 것과 데이터셋이 이미 정수로 인코딩 되어 있다는 특징이 있다. 고전적 머신러닝 모델의 입력으로 데이터셋을 TF-IDF 임베딩을 사용하고 딥러닝 모델의 입력으로는 별다른 전처리 없이 130 길이의 패딩 처리만 거친 후 데이터셋을 바로 사용하였다. 모델의 평가지표로 데이터가 클래스 별로 불균형하게 분포하기 때문에 F1-Score를 사용, 최종적으로 '단어사전 크기에 따른 모델의 성능'의 평균을 지표로 채택 하였다. 고전적 머신러닝 모델은 총 8개를 사용하였으며 딥러닝 모델로 1D Convolution 레이어를 이용한 모델을 채택하였다. 고전적 머신러닝 모델과 딥러닝 모델의 성능 차이를 확인한 결과, Voting(0.086), 로지스틱 회귀, 딥러닝, 선형 서포트 벡터 머신 등의 순으로 성능이 좋았다. 고전적 머신러닝 모델에 입력한 데이터의 경우 TF-IDF 임베딩을 사용하였지만, 딥러닝 모델에 입력한 데이터는 주어진 데이터를 별도의 전처리 없이 바로 사용하여, 딥러닝 모델의 뚜렷한 성능 향상을 도모하지 못한 것으로 판단하였다. 단어의 크기에 따른 성능 차이를 확인한 결과, 일관된 결과를 보여주지 않고 모델 별로 상이 하였다. 따라서 모델과 데이터에 따라 최적의 단어사전의 크기 설정은 상이하므로, 연구자가 이를 고려하여 다양한 시도를 할 필요가 있다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-metabolism",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 서론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 본 예제에서는 뉴스 본문을 입력하면 그에 대한 카테고리를 분류하는 모델을 생성하고 평가하는 것을 목표로 합니다. 이를 위해, 서포트 벡터 머신, 나이브 베이즈 등의 고전적 머신러닝과 딥러닝 모델을 사용 합니다. 또한, 단어사전 크기를 '모든 단어', '10,000개 단어', '5,000개 단어'로 구분하여 모델의 성능을 확인 합니다. 평가지표를 선택하여 최종적으로 각 모델 간 성능을 비교 합니다. 다음은 예제의 진행 순서를 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "> _1. 데이터 분석_\n",
    ">\n",
    "> _2. 데이터 전처리_\n",
    ">\n",
    "> _3. 고전적 머신러닝 모델 학습 및 평가_\n",
    ">\n",
    "> _4. 딥러닝 모델 학습 및 평가_\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-phase",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 데이터 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터셋을 분석 합니다. 데이터셋은 '로이터 뉴스 데이터'로, 뉴스 본문과 46개의 뉴스 카테고리 중 본문에 해당하는 하나의 값이 한 쌍으로 이루어져 있습니다. 단어사전의 크기에 따른 모델의 성능을 비교하기 위해 '모든 단어', '10,000개 단어', '5,000개 단어'를 사용하는 데이터셋을 구분하여 사용 합니다. 뉴스 본문은 토큰화가 이미 이루어져 정수 형태로 인코딩 되어 있으며, 학습 데이터는 8,982개, 테스트 데이터는 2,246개 입니다. 하나의 문서는 최대 2,376개, 평균 145개의 토큰으로 이루어져 있습니다. 또한, 46개의 클래스 별 데이터 분포가 불균형하게 존재함을 확인하였습니다. 따라서, 추후 모델 평가 시에 이를 고려한 평가지표를 선택할 필요가 있습니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-tournament",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 호출\n",
    "***\n",
    "+ 예제에 사용할 라이브러리를 호출 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elementary-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   #행렬 연산\n",
    "import pandas as pd   #데이터 프레임\n",
    "import seaborn as sns   #데이터 시각화\n",
    "import matplotlib.pyplot as plt   #데이터 시각화\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score #F1-score\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from sklearn.model_selection import train_test_split   #학습 데이터 분할\n",
    "\n",
    "\n",
    "import tensorflow as tf   #신경망\n",
    "from keras import backend as K   #케라스 F1-score\n",
    "from tensorflow.keras.datasets import reuters   #데이터셋\n",
    "from tensorflow.keras.utils import to_categorical   #원핫 인코딩\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   #패딩\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer   #DTM\n",
    "from sklearn.feature_extraction.text import TfidfTransformer   #TF-IDF\n",
    "\n",
    "\n",
    "#머신러닝 모델==========================================\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "#End===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-position",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터셋 불러오기\n",
    "***\n",
    "+ 예제에서 사용할 '로이터 뉴스 데이터를 불러옵니다.\n",
    "\n",
    "\n",
    "+ 단어사전 크기에 따른 성능 분석을 확인하기 위해 '모든 단어', '10,000개 단어', '5,000개 단어'로 구성된 데이터셋을 각각 불러옵니다.\n",
    "\n",
    "\n",
    "+ 학습 데이터는 8,982개, 테스트 데이터는 2,246개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "periodic-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "학습 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "(x_train_all, y_train_all), (x_test_all, y_test_all) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "(x_train_10th, y_train_10th), (x_test_10th, y_test_10th) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "(x_train_5th, y_train_5th), (x_test_5th, y_test_5th) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "\n",
    "print(\"*\" * 50)\n",
    "print('학습 샘플의 수: {}'.format(len(x_train_all)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test_all)))\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-quick",
   "metadata": {},
   "source": [
    "#### 학습 데이터 출처\n",
    "***\n",
    "+ Martin Thoma, The Reuters Dataset(2017), https://martin-thoma.com/nlp-reuters/\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-constitutional",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 기본 정보 확인\n",
    "***\n",
    "+ 입력 데이터는 이미 정수 형태로 인코딩 되어 있는 것을 확인할 수 있습니다.\n",
    "\n",
    "\n",
    "+ 정답 데이터는 하나의 정수 값으로 총 클래스는 46개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suburban-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================< TRAIN DATA >=======================\n",
      "[    1 27595 28842     8    43    10   447     5    25   207   270     5\n",
      "  3095   111    16   369   186    90    67     7    89     5    19   102\n",
      "     6    19   124    15    90    67    84    22   482    26     7    48\n",
      "     4    49     8   864    39   209   154     6   151     6    83    11\n",
      "    15    22   155    11    15     7    48     9  4579  1005   504     6\n",
      "   258     6   272    11    15    22   134    44    11    15    16     8\n",
      "   197  1245    90    67    52    29   209    30    32   132     6   109\n",
      "    15    17    12]\n",
      "\n",
      "TARGET DATA: 3\n",
      "============================================================\n",
      "클래스의 수 : 46\n"
     ]
    }
   ],
   "source": [
    "print(\"< TRAIN DATA >\".center(60, \"=\"))\n",
    "print(np.array(x_train_all[0]))\n",
    "\n",
    "print(\"\\nTARGET DATA:\", y_train_all[0])\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print('클래스의 수 : {}'.format(max(y_train_all) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-techno",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 길이 분석\n",
    "***\n",
    "+ 2,376개의 토큰로 이루어진 데이터가 최대 길이 이며, 평균 약 145개의 토큰으로 이루어져 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "least-mechanics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "plt.hist([len(s) for s in x_train_all], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "print(\"*\" * 50)\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train_all)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train_all))/len(x_train_all)))\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-wilson",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 클래스별 데이터 분포 시각화\n",
    "***\n",
    "+ 총 46개(0 ~ 45)의 클래스에 대한 학습 데이터의 분포를 시각화 합니다.\n",
    "\n",
    "\n",
    "+ 데이터 분포가 불균형 한 것을 확인할 수 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intimate-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqIAAAEvCAYAAACex6NoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhx0lEQVR4nO3de7xcZXno8d8DAbwiWEIMCZ5QjW2xrehJEVtrVSoEtAQQKdQLIh6sQgFrj4X2HFE5nHopUrFKi4KAN0SuKUYBqa3tOQoEBeRSJGosiVyiINjyEU/wOX+sNzBsZq1ZO9mz3+zk9/185rPXvPM+8757zTMzz6zLTGQmkiRJ0nTbovYEJEmStHmyEJUkSVIVFqKSJEmqwkJUkiRJVViISpIkqQoLUUmSJFUxq/YExmGHHXbIBQsW1J6GJEnSZu+66677UWbOHnbbJlmILliwgOXLl9eehiRJ0mYvIn7Qdpu75iVJklSFhagkSZKqsBCVJElSFRaikiRJqsJCVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVm+Rvzc8UP/zoO3r12+moU8Y8E0mSpOnnFlFJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVFqKSJEmqwkJUkiRJVViISpIkqYqxFaIR8YSIuCYiboiImyPiPaV9l4i4OiJWRMTnI2Lr0r5Nub6i3L5g4L5OKO23RcTe45qzJEmSps84t4g+BLw8M58H7AYsjog9gPcDp2bms4H7gCNK/yOA+0r7qaUfEbErcAjwXGAx8LGI2HKM85YkSdI0GFshmo3/KFe3KpcEXg5cUNrPAfYvy0vKdcrte0ZElPbzMvOhzPw+sALYfVzzliRJ0vQY6zGiEbFlRFwP3ANcCXwX+Elmri1dVgHzyvI84A6Acvv9wC8Ntg+JkSRJ0gw11kI0Mx/OzN2A+TRbMX91XGNFxJERsTwilq9Zs2Zcw0iSJGmKTMtZ85n5E+CrwIuA7SJiVrlpPrC6LK8GdgYotz8N+PFg+5CYwTHOyMxFmblo9uzZ4/g3JEmSNIXGedb87IjYriw/EXgFcCtNQXpQ6XYYcGlZXlquU27/x8zM0n5IOat+F2AhcM245i1JkqTpMWt0l/U2FzinnOG+BXB+Zl4WEbcA50XE/wK+BZxZ+p8JfCoiVgD30pwpT2beHBHnA7cAa4GjMvPhMc5bkiRJ02BshWhm3gg8f0j79xhy1ntm/gx4Tct9nQycPNVzlCRJUj3+spIkSZKqsBCVJElSFRaikiRJqsJCVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVFqKSJEmqwkJUkiRJVViISpIkqQoLUUmSJFVhISpJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKqsBCVJElSFRaikiRJqsJCVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVMXYCtGI2DkivhoRt0TEzRFxbGl/d0Ssjojry2XfgZgTImJFRNwWEXsPtC8ubSsi4vhxzVmSJEnTZ9YY73st8I7M/GZEPBW4LiKuLLedmpl/Pdg5InYFDgGeC+wEfCUinlNu/ijwCmAVcG1ELM3MW8Y4d0mSJI3Z2ArRzLwTuLMs/zQibgXmdYQsAc7LzIeA70fECmD3ctuKzPweQEScV/paiEqSJM1g03KMaEQsAJ4PXF2ajo6IGyPirIjYvrTNA+4YCFtV2traJUmSNIONvRCNiKcAFwLHZeYDwOnAs4DdaLaYnjJF4xwZEcsjYvmaNWum4i4lSZI0RmMtRCNiK5oi9DOZeRFAZt6dmQ9n5i+Aj/Po7vfVwM4D4fNLW1v7Y2TmGZm5KDMXzZ49e+r/GUmSJE2pcZ41H8CZwK2Z+aGB9rkD3Q4AbirLS4FDImKbiNgFWAhcA1wLLIyIXSJia5oTmpaOa96SJEmaHuM8a/53gNcD346I60vbXwCHRsRuQAIrgbcAZObNEXE+zUlIa4GjMvNhgIg4Grgc2BI4KzNvHuO8JUmSNA3Gedb8vwIx5KZlHTEnAycPaV/WFSdJkqSZx19WkiRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKqsBCVJElSFRaikiRJqsJCVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVFqKSJEmqwkJUkiRJVViISpIkqQoLUUmSJFVhISpJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKqGFshGhE7R8RXI+KWiLg5Io4t7U+PiCsj4vbyd/vSHhFxWkSsiIgbI+IFA/d1WOl/e0QcNq45S5IkafqMc4voWuAdmbkrsAdwVETsChwPXJWZC4GrynWAfYCF5XIkcDo0hStwIvBCYHfgxHXFqyRJkmausRWimXlnZn6zLP8UuBWYBywBzindzgH2L8tLgHOz8Q1gu4iYC+wNXJmZ92bmfcCVwOJxzVuSJEnTY1qOEY2IBcDzgauBOZl5Z7npLmBOWZ4H3DEQtqq0tbVLkiRpBht7IRoRTwEuBI7LzAcGb8vMBHKKxjkyIpZHxPI1a9ZMxV1KkiRpjMZaiEbEVjRF6Gcy86LSfHfZ5U75e09pXw3sPBA+v7S1tT9GZp6RmYsyc9Hs2bOn9h+RJEnSlBvnWfMBnAncmpkfGrhpKbDuzPfDgEsH2t9Qzp7fA7i/7MK/HNgrIrYvJyntVdokSZI0g80a433/DvB64NsRcX1p+wvgfcD5EXEE8APg4HLbMmBfYAXwIHA4QGbeGxEnAdeWfu/NzHvHOG9JkiRNg7EVopn5r0C03LznkP4JHNVyX2cBZ03d7Gaulaft37vvgmMuGds8JEmSNpS/rCRJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKq6FWIRsRVfdokSZKkvmZ13RgRTwCeBOwQEdsDUW7aFpg35rlJkiRpE9ZZiAJvAY4DdgKu49FC9AHgb8c3LUmSJG3qOgvRzPww8OGI+JPM/Mg0zUmSJEmbgVFbRAHIzI9ExG8DCwZjMvPcMc1LkiRJm7hehWhEfAp4FnA98HBpTsBCVJIkSeulVyEKLAJ2zcwc52QkSZK0+ej7PaI3Ac8Y50QkSZK0eem7RXQH4JaIuAZ4aF1jZu43lllJkiRpk9e3EH33OCchSZKkzU/fs+b/edwTkSRJ0ual71nzP6U5Sx5ga2Ar4D8zc9txTUySJEmbtr5bRJ+6bjkiAlgC7DGuSUmSJGnT1/es+Udk4xJg76mfjiRJkjYXfXfNHzhwdQua7xX92VhmJEmSpM1C37Pm/2BgeS2wkmb3vCRJkrRe+h4jevi4JyJJkqTNS69jRCNifkRcHBH3lMuFETF/3JOTJEnSpqvvyUqfBJYCO5XLP5Q2SZIkab30LURnZ+YnM3NtuZwNzB7jvCRJkrSJ61uI/jgiXhcRW5bL64Afj3NikiRJ2rT1LUTfBBwM3AXcCRwEvLErICLOKseT3jTQ9u6IWB0R15fLvgO3nRARKyLitojYe6B9cWlbERHHT+J/kyRJ0kasbyH6XuCwzJydmTvSFKbvGRFzNrB4SPupmblbuSwDiIhdgUOA55aYj63b+gp8FNgH2BU4tPSVJEnSDNe3EP3NzLxv3ZXMvBd4fldAZn4NuLfn/S8BzsvMhzLz+8AKYPdyWZGZ38vMnwPn4feXSpIkbRL6FqJbRMT2665ExNPp/2X4Ex0dETeWXffr7nMecMdAn1Wlra1dkiRJM1zfQvQU4OsRcVJEnAT8X+AD6zHe6cCzgN1ojjU9ZT3uY6iIODIilkfE8jVr1kzV3UqSJGlMehWimXkucCBwd7kcmJmfmuxgmXl3Zj6cmb8APk6z6x1gNbDzQNf5pa2tfdh9n5GZizJz0ezZfrOUJEnSxq737vXMvAW4ZUMGi4i5mXlnuXoAsO6M+qXAZyPiQzRfmL8QuAYIYGFE7EJTgB4C/NGGzEGSJEkbh/U9znOkiPgc8FJgh4hYBZwIvDQidgMSWAm8BSAzb46I82kK3bXAUZn5cLmfo4HLgS2BszLz5nHNWZIkSdNnbIVoZh46pPnMjv4nAycPaV8GLJvCqUmSJGkj0PdkJUmSJGlKWYhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKqsBCVJElSFRaikiRJqsJCVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVFqKSJEmqwkJUkiRJVViISpIkqQoLUUmSJFVhISpJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKqsBCVJElSFRaikiRJqmJshWhEnBUR90TETQNtT4+IKyPi9vJ3+9IeEXFaRKyIiBsj4gUDMYeV/rdHxGHjmq8kSZKm1zi3iJ4NLJ7QdjxwVWYuBK4q1wH2ARaWy5HA6dAUrsCJwAuB3YET1xWvkiRJmtnGVohm5teAeyc0LwHOKcvnAPsPtJ+bjW8A20XEXGBv4MrMvDcz7wOu5PHFrSRJkmag6T5GdE5m3lmW7wLmlOV5wB0D/VaVtrZ2SZIkzXDVTlbKzARyqu4vIo6MiOURsXzNmjVTdbeSJEkak+kuRO8uu9wpf+8p7auBnQf6zS9tbe2Pk5lnZOaizFw0e/bsKZ+4JEmSptZ0F6JLgXVnvh8GXDrQ/oZy9vwewP1lF/7lwF4RsX05SWmv0iZJkqQZbta47jgiPge8FNghIlbRnP3+PuD8iDgC+AFwcOm+DNgXWAE8CBwOkJn3RsRJwLWl33szc+IJUJIkSZqBxlaIZuahLTftOaRvAke13M9ZwFlTODVJkiRtBPxlJUmSJFVhISpJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKqsBCVJElSFRaikiRJqsJCVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVFqKSJEmqwkJUkiRJVViISpIkqQoLUUmSJFVhISpJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpilk1Bo2IlcBPgYeBtZm5KCKeDnweWACsBA7OzPsiIoAPA/sCDwJvzMxv1pi3pI3bvhd/oHffZQe8c4wzkST1UXOL6Msyc7fMXFSuHw9clZkLgavKdYB9gIXlciRw+rTPVJIkSVNuY9o1vwQ4pyyfA+w/0H5uNr4BbBcRcyvMT5IkSVOoViGawBURcV1EHFna5mTmnWX5LmBOWZ4H3DEQu6q0SZIkaQarcowo8OLMXB0ROwJXRsS/Dd6YmRkROZk7LAXtkQDPfOYzp26mkiRJGosqW0Qzc3X5ew9wMbA7cPe6Xe7l7z2l+2pg54Hw+aVt4n2ekZmLMnPR7Nmzxzl9SZIkTYFpL0Qj4skR8dR1y8BewE3AUuCw0u0w4NKyvBR4QzT2AO4f2IUvSZKkGarGrvk5wMXNtzIxC/hsZn45Iq4Fzo+II4AfAAeX/stovrppBc3XNx0+/VOWJEnSVJv2QjQzvwc8b0j7j4E9h7QncNQ0TE3SCPss3a933y/tt3SMM5EkbQpqnay00Vrzd3/fu+/sP37LGGciSZK0aduYvkdUkiRJmxELUUmSJFVhISpJkqQqPEZU6uHMc/fq1e+IN1wx5plIkrTpcIuoJEmSqrAQlSRJUhUWopIkSarCQlSSJElVWIhKkiSpCgtRSZIkVWEhKkmSpCosRCVJklSFhagkSZKq8JeVJG32XnnRab36ffHAY8Y8E0navLhFVJIkSVVYiEqSJKkKC1FJkiRVYSEqSZKkKixEJUmSVIWFqCRJkqqwEJUkSVIVfo+otBH5wOf27t33nYdePsaZSJI0fm4RlSRJUhVuEdVG4Utn7tur3z5HLBvzTCRJ0nRxi6gkSZKqcIuoNiufObv/MZivfaPHYEqSNE5uEZUkSVIVbhHVjHXRJxf37nvg4V8e40y0OXrlhX/fu+8XX/2WMc5k6vzBBZf27vsPBy0Z40wkbS7cIipJkqQq3CI6Be4+/QO9+8556zvHOBNp07HvxSf27rvsgPeMcSaSpHHZpAvRNad/ule/2W993ZhnIknT61UXfKF338sOes0YZyJJ7WZMIRoRi4EPA1sCn8jM91We0ibv6r9/Ve++L3zLZWOcycz0t5/uf4b+0a/zDH21e9UFn+nV77KDXjvmmdR14IVf7933ole/aIPG+sOLvte77+cP/OUNGmu6XPqFH/Xuu+Q1O2zQWF8/Z03vvi86bPYGjaWZbUYUohGxJfBR4BXAKuDaiFiambfUnZmkPva55Jhe/b60/2ljnok0PidcvLp33786YN4jyx+++K5eMcce8IxJz0lT665Tbu/V7xnvWPjI8t2n3tD7/ue8/XmTntNMNyMKUWB3YEVmfg8gIs4DlgAWoj19+2P79er3G29bukHjfPUTr+zd92Vv/uIGjaVH/c/z+32DwEkHP/rtAW+7qP+3DnzsQL91QO2WXNAvPy49qH/OTaWDLuxXCFzw6s2vCNiY3PDxe3r3fd5/2/GR5RUfubt33LP/ZA4Ad77/zt4xc/98bu++td192j/16jfnmJdu0Dj3fPTi3n13POqAzttnSiE6D7hj4Poq4IWV5iJJ6+VVF57du+9lr37j2OaxMdj/wq/27nvJq182xpnMTJ+6qP+u79cfuGG7vr/y2X5j/f4fuYt9qtz94W/07jvn2D02aKx7/vZLvfvuePQ+GzTWMJGZU36nUy0iDgIWZ+aby/XXAy/MzKMH+hwJHFmu/gpwW8vd7QD0P1Bm/WOmc6yNfX7TOZbzm/6Y6RzL+U1/zHSO5fymP2Y6x9rY5zedY21u8/svmTn8k0pmbvQX4EXA5QPXTwBOWM/7Wj4dMdM51sY+P9eF83N+G8dYzs/5Ob+NYyzn9+hlpnyh/bXAwojYJSK2Bg4BNuxgRkmSJFU1I44Rzcy1EXE0cDnN1zedlZk3V56WJEmSNsCMKEQBMnMZsGwK7uqMaYqZzrE29vlN51jOb/pjpnMs5zf9MdM5lvOb/pjpHGtjn990juX8ihlxspIkSZI2PTPlGFFJkiRtatbnrKiZegEW03yt0wrg+B79zwLuAW6axBg7A1+l+bL9m4Fje8Y9AbgGuKHEvWcSY24JfAu4rGf/lcC3geuZxBluwHbABcC/AbcCLxrR/1fKGOsuDwDH9Rjn7WUd3AR8DnhCz/kdW2Jubhtn2GMKPB24Eri9/N2+Z9xryli/ABb1jPlgWX83AhcD2/WIOan0vx64AthpMrkKvANIYIceY70bWD3wmO3bZxzgT8r/dTPwgZ7r4vMD46wEru8RsxvwjXW5C+zeI+Z5wNdpcv4fgG37PGdH5UVHXGtedMS05kVHTGdetMV15UXHWK150TVOV150jNWaFx0xrXnRETMqL4a+JgO7AFfTvI98Hti6R8zRpf/jnocj4j5D8551E01ub9Uj5szSdiPN6/VTRsUM3H4a8B+TmN/ZwPcHHq/desQEcDLwHZr3kWN6xPzLwBg/BC7pOb89gW+WuH8Fnt0j5uUl5ibgHGDWkPXxmPfcrpzoiOnMiY641pzoiGnNibaYUTnRMVZrTrTex6gOm8qlrKzvAr8MbF0elF1HxLwEeAGTK0TnAi8oy08tT7bOcUrfWJccwFYlqffoOeafAp+dmEAd/Vd2JX5H3DnAm8vy1kwoonqs/7tovkusq9+8ksRPLNfPB97Y4/5/vTwxn0Rz7PNXBl90uh5T4AOUDybA8cD7e8b9Gk2x/U8ML0SHxexFeWED3j9xrJaYbQeWjwH+rm+u0rwJXw78YOJj3jLWu4E/m8xzAnhZWd/blOs79p3fwO2nAO/qMdYVwD5leV/gn3rEXAv8Xll+E3DShJihz9lRedER15oXHTGtedER05kXbXFdedExVmtedMR05kXX/NryomOs1rzoiBmVF0Nfk2lekw4p7X8HvLVHzPOBBbS89nbE7VtuC5oP5X3GGsyLDzGw0aUtplxfBHyK4YVo21hnAwe15EVbzOHAucAWE/Oia34DfS4E3tBzrO8Av1ba3wacPSLmt2l+POc5pf29wBFD/rfHvOd25URHTGdOdMS15kRHTGtOtMWMyomOsVpzou2yOe2af+RnQjPz58C6nwltlZlfA+6dzCCZeWdmfrMs/5TmE9+87ijIxn+Uq1uVS46Ki4j5wCuBT0xmnpMVEU+jeZM/EyAzf56ZP5nEXewJfDczf9Cj7yzgiRExi6aw/GGPmF8Drs7MBzNzLfDPwIETO7U8pktoimzK3/37xGXmrZnZ9sMJbTFXlPlBswVnfo+YBwauPpkhedGRq6cC75xkTKuWmLcC78vMh0qfx/1OX9dYERHAwTQvqqNiEti2LD+NCbnREvMc4Gtl+Urg1RNi2p6znXnRFteVFx0xrXnREdOZFyNei4bmxfq8fnXEdObFqLGG5UVHTGtedMSMyou21+SX02xVggl50RaTmd/KzJUd67Atblm5LWm23s3vEfPAwPp7IgOPcVtMRGxJs1X+nZOZX9v/MyLmrcB7M/MXpd89PWIo/9O2NOv/kp5jdeXFsJiHgZ9n5ndK++PyYuJ7blnPrTkxLKaM35kTHXGtOdER05oTbTGjcqItbn1sToXosJ8JHVkgboiIWEDzqefqnv23jIjraXYtXpmZfeL+hiZRfjGJqSVwRURcV36Rqo9dgDXAJyPiWxHxiYh48iTGPIQJhcbQiWWuBv4a+HfgTuD+zLyix/3fBPxuRPxSRDyJ5lPjzj3nNicz1/3w8F3AnJ5xG+pNQK/fVouIkyPiDuC1wLt6xiwBVmdmvx/aftTREXFjRJwVEdv36P8cmnV/dUT8c0T81iTH+13g7sy8vUff44APlnXx1zQ/bjHKzTz6ofM1dOTFhOds77yY7HN9RExrXkyM6ZsXg3F982LI/EbmxYSY3nnRsi4682JCzHH0yIsJMSPzYuJrMs1etZ8MfGh43PvIer6Od8ZFxFbA64Ev94mJiE/S5OyvAh/pEXM0sHQg3yczv5NLXpwaEdv0iHkW8IcRsTwivhQRC/uuB5oC76oJH8K64t4MLIuIVWX9va8rhqawmxURi0qXg3h8XvwNj33P/SVG5MSQmL5a49pyoi2mKydaYkbmRMf8WnNimM2pEJ1WEfEUml0Ixw170gyTmQ9n5m40n3B2j4hfHzHGq4B7MvO6SU7vxZn5AmAf4KiIeEmPmFk0uzxPz8znA/9Js7typPIjBPsBX+jRd3uaN4ddgJ2AJ0fE60bFZeatNLs0r6B5Yl5P8+l2UsqnzJFbojdURPwlsJbmeJ+RMvMvM3Pn0v/oUf1LMf4X9CxaB5xO80axG80HgVN6xMyiOZ5yD+C/A+eXT959HUqPDynFW4G3l3XxdsoW+hHeBLwtIq6j2TX782Gdup6zXXmxPs/1tpiuvBgW0ycvBuPKfY/MiyFjjcyLITG98qJj/bXmxZCYkXkxJGZkXkx8TaZ5E+802dfxnnEfA76Wmf/SJyYzD6d5/bwV+MMRMS+hKcQnFid95ncCzTr5LZrH+s97xGwD/CwzFwEfpznOse96aM2Jlri30xzPPB/4JM1u6dYY4Lk0G01OjYhrgJ8y8D6yPu+56/s+3SPucTnRFdOWE8NiImInRuREx1idOTFUTmI//ky+sJ4/E0pzDEfvY0RLzFY0x1/96QbM9110HKtX+vwVzaevlTSfdB4EPj3Jcd49apzS7xnAyoHrvwt8secYS4ArevZ9DXDmwPU3AB9bj/X3v4G39XlMaQ78nluW5wK3TSYXaDlGtC0GeCPNSRJPmmzOAc/suO2ROOA3aD7lryyXtTRbmZ8xibHa/t+J6+/LwMsGrn8XmN1zXcwC7gbm93ys7ufRr50L4IFJrr/nANcMaX/cc7ZPXgyLG5UXbTFdedE1TldeTIzrkxc9xhr2OA5bfyPzomNdtOZFy1idedHjfxqaFxP6vIumoP4Rjx7P+5j3lZaYPxu4vpIex+cPxgEn0uyK3qJvzEDbS+g4d6DEnEjz/rEuJ35BcxjbZMd6aY+x/ozm5LVdBh6r+3uuhx2AH9Pj5NWBx+q7E54jt0zyf9oLOH/g+rD33M905URLzKcHbh+aE11xbTkxaqxhOdESc9+onOg5VmdOrLtsTltEp+VnQssn/jOBWzPzQ6P6D8TNjojtyvITgVfQPGFbZeYJmTk/MxfQ/D//mJmdWw8j4skR8dR1yzRPtJtGzS8z7wLuiIhfKU170pyF2sdktnj9O7BHRDyprMs9aT7BjRQRO5a/z6Q5PvSzPcdcChxWlg8DLu0ZN2kRsZhmV8Z+mflgz5jBXVdLGJEXAJn57czcMTMXlPxYRXPCxl0jxpo7cPUAeuQGzQviy0r8c2hOZPtRjziA3wf+LTNX9ez/Q+D3yvLLac5o7zSQF1sA/4PmZILB29ues515sT7P9baYrrzoiOnMi2Fxo/KiY6zWvOhYD5fQkRcj1t/QvOiIac2Ljv9pVF4Me02+leYM/INKt8fkxfq8jnfFRcSbgb2BQ7McUzki5raIePbA/73f4PgtMddl5jMGcuLBzHx2z/nNHRhrfx6bF23r4hJKXtA8Zt/pEQPNOr8sM3/Wc/3dCjyt5B4DbaP+p3V5sQ3N1rxH8qLlPfe1dOTE+rxPd8V15cSwGOD1XTnRMs72o3KiY36tOdH1z242F5rjBr9D88n8L3v0/xzNbqj/R/OC/biz54bEvJhmF966r1W5nglfgdMS95s0X4FwY3ng3jUqZkL8S+nxyYPmWwNu4NGvrBi5HgZid6P5apQbaV5MHvc1R0NinkzzKfZpkxjnPeWJchPNGXvb9Iz7F5ri+AZgz76PKc0xPlfRvHl9BXh6z7gDyvJDNFtvLu8Rs4LmWOV1uTHxTOdhMReWdXEjzdfMzJtsrjLkU3fLWJ+i+TqbG2kKsbk9YrYGPl3m+E3g5X3nR3OG5R9P4rF6MXBdeYyvBv5rj5hjaZ7336E5Riz6PGdH5UVHXGtedMS05kVHTGdetMV15UXHWK150RHTmRdd86MlLzrGas2LjphReTH0NZnmNfSa8ph9gYHXp46YY2hyYi1N0fyJnmOtpXm/Wjfvd3XF0Bxu93/KY3UTzda6bUeNM2Euw86ab5vfPw6M9Wke+1VRbTHbAV8scV8HntdnfjR7GBa3vFa0jXVAGeeGEv/LPWI+SFOw3kbH1w0y8J7blRMdMZ050RHXmhPDYkblRNs4o3KiY36tOdF28ZeVJEmSVMXmtGtekiRJGxELUUmSJFVhISpJkqQqLEQlSZJUhYWoJEmSqrAQlSRJUhUWopIkSarCQlSSJElV/H8l+W2v1F85sAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-creator",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 클래스별 데이터 분포 분석\n",
    "***\n",
    "+ 총 46개(0 ~ 45)의 클래스 정보와 학습 데이터의 분포를 출력 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resistant-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================< 각 클래스 빈도수 >============================================\n",
      "    0(cocoa)   : 55\t    1(grain)   : 432\t   2(veg-oil)  : 74\t    3(earn)    : 3159\t     4(acq)    : 1949\t\n",
      "\n",
      "    5(wheat)   : 17\t   6(copper)   : 48\t   7(housing)  : 16\t8(money-supply): 139\t   9(coffee)   : 101\t\n",
      "\n",
      "   10(sugar)   : 124\t   11(trade)   : 390\t  12(reserves) : 49\t    13(ship)   : 172\t   14(cotton)  : 26\t\n",
      "\n",
      "  15(carcass)  : 20\t   16(crude)   : 444\t  17(nat-gas)  : 39\t    18(cpi)    : 66\t  19(money-fx) : 549\t\n",
      "\n",
      "  20(interest) : 269\t    21(gnp)    : 100\t 22(meal-feed) : 15\t    23(alum)   : 41\t  24(oilseed)  : 62\t\n",
      "\n",
      "    25(gold)   : 92\t    26(tin)    : 24\t27(strategic-metal): 15\t 28(livestock) : 48\t   29(retail)  : 19\t\n",
      "\n",
      "    30(ipi)    : 45\t 31(iron-steel): 39\t   32(rubber)  : 32\t    33(heat)   : 11\t    34(jobs)   : 50\t\n",
      "\n",
      "    35(lei)    : 10\t    36(bop)    : 49\t    37(zinc)   : 19\t   38(orange)  : 19\t  39(pet-chem) : 24\t\n",
      "\n",
      "    40(dlr)    : 36\t    41(gas)    : 30\t   42(silver)  : 13\t    43(wpi)    : 21\t    44(hog)    : 12\t\n",
      "\n",
      "    45(lead)   : 18\t\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "dataset_class = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    " 'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    " 'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    " 'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    " 'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']\n",
    "#https://github.com/SteffenBauer/KerasTools/tree/master/Reuters_Analysis\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "_, counts_elements = np.unique(y_train_all, return_counts=True)\n",
    "\n",
    "print(\"< 각 클래스 빈도수 >\".center(100, \"=\"))\n",
    "for idx, count in enumerate(counts_elements):\n",
    "    topic = f\"{idx}({dataset_class[idx]})\".center(15)\n",
    "    print(f\"{topic}: {count}\", end=\"\\t\")\n",
    "    if (idx+1) % 5 == 0:\n",
    "        print(\"\\n\")\n",
    "print(\"\\n\" + \"=\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-avatar",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. 데이터 전처리\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 뉴스 본문을 고전적 머신러닝 모델에 입력하기 위해, TF-IDF 형태로 변환한 합니다. TF-IDF는 단어의 빈도 뿐만아니라 문서 간 단어 사용 정도를 바탕으로 단어의 중요 정도에 대한 정보 내제하고 있는 임베딩 기법 입니다. 따라서, TF-IDF를 사용함으로써 뉴스 본문으로부터 중요 단어를 판단할 수 있고 이는 모델이 본문이 해당하는 카테고리를 판단하는 데에 중요한 변수로 작용 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-imaging",
   "metadata": {},
   "source": [
    "#### 단어사전 생성하기\n",
    "***\n",
    "+ 단어사전을 생성하고 일부를 출력 합니다.\n",
    "\n",
    "\n",
    "+ 총 30,982개의 토큰이 등록되어 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "arabic-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====< vocab >======\n",
      "10999: mdbl\n",
      "16263: fawc\n",
      "12092: degussa\n",
      "8806: woods\n",
      "13799: hanging\n",
      "20675: localized\n",
      "20676: sation\n",
      "20678: chanthaburi\n",
      "11000: refunding\n",
      "8807: hermann\n",
      "20679: passsengers\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "(skip)\n",
      "====================\n",
      "vocab size: 30982\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")   #단어장\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items()}\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "    \n",
    "#출력부==================================\n",
    "print(\"< vocab >\".center(20, \"=\"))\n",
    "for idx, (key, value) in enumerate(index_to_word.items()):\n",
    "    print(f\"{key}: {value}\")\n",
    "    if idx == 10: break;\n",
    "print(\".\\n\" * 3)\n",
    "print(\"(skip)\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "print(\"vocab size:\", len(index_to_word))\n",
    "#End====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-defense",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 단어 크기에 따른 디코더 결과 출력\n",
    "***\n",
    "+ 앞서 생성한 단어 크기별 데이터셋에 따른 디코더 결과를 확인 합니다.\n",
    "\n",
    "\n",
    "+ `<unk>` 토큰을 식별하기 위해 `★`을 함께 출력 합니다.\n",
    "\n",
    "\n",
    "+ 모든 단어를 이용하는 데이터셋의 경우 `<unk>` 토큰이 존재하지 않지만, 10,000개, 5,000개의 단어만을 이용하는 데이터셋의 경우 `<unk>` 토큰을 확인할 수 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comprehensive-remedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================< ALL Vocab >==================================\n",
      "<sos> the yield on 180 day bankers security deposit accounts issued this week by the saudi arabian monetary agency sama rose slightly to 6 63492 pct from 6 56823 last week bankers said sama reduced the offer price on the 500 mln riyal issue to 96 78906 from 96 82031 last week like dated interbank deposits were quoted today at seven 6 3 4 pct sama offers a total 1 9 billion riyals in 30 91 and 180 day paper to banks in bahrain each week reuter 3\n",
      "================================================================================\n",
      "\n",
      "================================< 10,000 Vocab >================================\n",
      "<sos> the yield on 180 day bankers security deposit accounts issued this week by the saudi arabian monetary agency sama rose slightly to 6 ★<UNK>★ pct from 6 ★<UNK>★ last week bankers said sama reduced the offer price on the 500 mln riyal issue to 96 ★<UNK>★ from 96 ★<UNK>★ last week like dated interbank deposits were quoted today at seven 6 3 4 pct sama offers a total 1 9 billion riyals in 30 91 and 180 day paper to banks in bahrain each week reuter 3\n",
      "================================================================================\n",
      "\n",
      "================================< 5,000 Vocab >=================================\n",
      "<sos> the yield on 180 day bankers security deposit accounts issued this week by the saudi arabian monetary agency ★<UNK>★ rose slightly to 6 ★<UNK>★ pct from 6 ★<UNK>★ last week bankers said ★<UNK>★ reduced the offer price on the 500 mln riyal issue to 96 ★<UNK>★ from 96 ★<UNK>★ last week like dated interbank deposits were quoted today at seven 6 3 4 pct ★<UNK>★ offers a total 1 9 billion riyals in 30 91 and 180 day paper to banks in bahrain each week reuter 3\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sentence(data):\n",
    "    sentence = []\n",
    "    for index in data:\n",
    "        if index == 2:\n",
    "            sentence.append(\"★<UNK>★\")\n",
    "            continue\n",
    "        sentence.append(index_to_word[index])\n",
    "    return \" \".join(sentence)\n",
    "\n",
    "\n",
    "print(\"< ALL Vocab >\".center(80, \"=\"))\n",
    "print(decode_sentence(x_train_all[2021]))\n",
    "print(\"=\" * 80, end=\"\\n\\n\")\n",
    "\n",
    "print(\"< 10,000 Vocab >\".center(80, \"=\"))\n",
    "print(decode_sentence(x_train_10th[2021]))\n",
    "print(\"=\" * 80, end=\"\\n\\n\")\n",
    "\n",
    "print(\"< 5,000 Vocab >\".center(80, \"=\"))\n",
    "print(decode_sentence(x_train_5th[2021]))\n",
    "print(\"=\" * 80, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-basics",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 디코딩\n",
    "***\n",
    "+ 정수로 이루어진 데이터를 문자로 디코딩 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "assured-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_str(data):\n",
    "    decoded = []\n",
    "    for i in range(len(data)):\n",
    "        t = ' '.join([index_to_word[index] for index in data[i]])\n",
    "        decoded.append(t)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "x_train_str_all, x_test_str_all = int_to_str(x_train_all), int_to_str(x_test_all)\n",
    "x_train_str_10th, x_test_str_10th = int_to_str(x_train_10th), int_to_str(x_test_10th)\n",
    "x_train_str_5th, x_test_str_5th = int_to_str(x_train_5th), int_to_str(x_test_5th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-nigeria",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### TF-IDF 획득\n",
    "***\n",
    "+ 문자로 변환된 데이터를 바탕으로 TF-IDF를 획득 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sapphire-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "def get_TF_IDF(train, test):\n",
    "    x_train_dtm = dtmvector.fit_transform(train)   #DTM\n",
    "    tfidfv = tfidf_transformer.fit_transform(x_train_dtm)   #TF-IDF\n",
    "    \n",
    "    x_test_dtm = dtmvector.transform(test) #테스트 데이터를 DTM으로 변환\n",
    "    tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "\n",
    "    return (tfidfv, tfidfv_test)\n",
    "\n",
    "\n",
    "tfidfv_train_all, tfidfv_test_all = get_TF_IDF(x_train_str_all, x_test_str_all)\n",
    "tfidfv_train_10th, tfidfv_test_10th = get_TF_IDF(x_train_str_10th, x_test_str_10th)\n",
    "tfidfv_train_5th, tfidfv_test_5th = get_TF_IDF(x_train_str_5th, x_test_str_5th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-spotlight",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. 머신러닝 모델 학습 및 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 앞서 생성한 TF-IDF 임베딩을 사용하여 고전 머신러닝 모델을 학습하고 평가합니다. 카테고리 별 데이터 분포가 불균형한 것을 근거로 모델의 평가지표로 F1-Score를 사용 합니다. F1-Score Weighted와 Micro는 클래스 별 존재하는 불균형을 고려한 평균으로 예제에서는 모델의 성능을 평가하기 위해 Weighted를 평가지표로 사용 합니다. 또한, 단어 크기 별 모델의 F1-Score의 평균을 최종 성능으로 판단 합니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 머신러닝 모델은 총 8개로 '나이브 베이즈', '컴플리먼트 나이브 베이즈', '로지스틱 회귀', '선형 서포트 벡터 머신', '결정 트리', '랜덤 포레스트', '그래디언트 부스팅 트리', '보팅'을 사용합니다. [표 1]은 고전적 머신러닝 모델의 성능과 순위를 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "|Rank|Model|(all / 10,000 / 5,000) F1-Score(weight)|F1-Score(weight) Avg|\n",
    "|:--------:|:--------:|:--------:|:--------:|\n",
    "|1|**Voting(Logistic Regression + CNB)**|0.81 / 0.805 / 0.803|0.806|\n",
    "|2|**Logistic Regression**|0.812 / 0.806 / 0.798|0.805|\n",
    "|3|**Linear Support Vector Machine**|0.781 / 0.781 / 0.774|0.779|\n",
    "|4|**GBC**|0.748 / 0.743 / 0.749|0.747|\n",
    "|5|**CNB**|0.735 / 0.746 / 0.746|0.742|\n",
    "|6|**Random Forest**|0.623 / 0.643 / 0.677|0.648|\n",
    "|7|**Decision Tree**|0.577 / 0.578 / 0.573|0.576|\n",
    "|8|**Naive Bayes**|0.505 / 0.576 / 0.601|0.561|\n",
    "\n",
    "[표 1] 고전적 머신러닝 모델 성능\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-reserve",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습, 모델 성능 출력 함수 생성\n",
    "***\n",
    "+ `test_model` 함수를 통해 모델을 생성 및 학습 합니다.\n",
    "\n",
    "\n",
    "+ `print_model_result` 함수를 통해 모델 성능(`Accuracy`, `F1-Score`)을 출력 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tropical-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, train_x, train_y, test_x, test_y):\n",
    "    model.fit(train_x, train_y)\n",
    "    predict = model.predict(test_x)\n",
    "    \n",
    "    accuracy = accuracy_score(test_y, predict)\n",
    "    f1_weight = f1_score(test_y, predict, average=\"weighted\")\n",
    "    f1_micro = f1_score(test_y, predict, average=\"micro\")\n",
    "    return (accuracy, f1_weight, f1_micro)\n",
    "\n",
    "\n",
    "def print_model_result(acc, f1_w, f1_m, title):\n",
    "    print(f\"< {title} >\".center(30, \"*\"))\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"F1-Score(Weight):\", round(f1_w, 3))\n",
    "    print(\"F1-Score(Micro):\", round(f1_m, 3))\n",
    "    print(\"*\" * 30, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-packet",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 나이브 베이즈(Naive Bayes)\n",
    "***\n",
    "+ 나이브 베이즈는 연산 효율이 좋아 큰 데이터를 처리하는 데에 있어 유용 하며, 연속 데이터에 비해 이산 데이터에서 성능이 좋습니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '5,000개의 단어 사용(0.601)', '10,000개의 단어 사용(0.576)', '모든 단어 사용(0.505)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-madison",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "\n",
    "+ _나이브 베이즈는 '이산 데이터'에 대해 성능이 좋지만, 해당 데이터는 TF-IDF의 임베딩 벡터로 연속 데이터이므로 그다지 좋지 않은 성능을 보이는 것 같습니다._\n",
    "\n",
    "\n",
    "+ _LMS 본문에서는 '나이브 베이즈'가 조건부 독립을 전제로 연산하기 때문에 샘플이 특정 클래스에 치우칠 경우, 모델의 출력도 이에 따라 편향 된다고 하였습니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smaller-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.6\n",
      "F1-Score(Weight): 0.505\n",
      "F1-Score(Micro): 0.6\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.657\n",
      "F1-Score(Weight): 0.576\n",
      "F1-Score(Micro): 0.657\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.673\n",
      "F1-Score(Weight): 0.601\n",
      "F1-Score(Micro): 0.673\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc, f1_w, f1_m = test_model(MultinomialNB(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "\n",
    "acc, f1_w, f1_m = test_model(MultinomialNB(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "\n",
    "acc, f1_w, f1_m = test_model(MultinomialNB(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-litigation",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Complement Naive Bayes(CNB)\n",
    "***\n",
    "+ CNB는 나이브 베이즈의 불균형한 데이터에서 발생하는 편향 문제를 해결하기 위해 제시되어 불균형에 따라 가중치를 적용하여 문제를 해결하는 모델 입니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '5,000개의 단어 사용(0.746)'와 '10,000개의 단어 사용(0.746)'의 경우 성능이 동일하며, '모든 단어 사용(0.735)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-construction",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _기존 나이브 베이즈 모델의 성능 보다 향상된 것을 확인할 수 있으며, 이는 CNB가 불균형한 데이터에 강건함을 잘 보여 줍니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "naked-railway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.673\n",
      "F1-Score(Weight): 0.735\n",
      "F1-Score(Micro): 0.765\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.771\n",
      "F1-Score(Weight): 0.746\n",
      "F1-Score(Micro): 0.771\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.771\n",
      "F1-Score(Weight): 0.746\n",
      "F1-Score(Micro): 0.771\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cc, f1_w, f1_m = test_model(ComplementNB(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(ComplementNB(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(ComplementNB(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-trust",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 로지스틱 회귀(Logistic Regression)\n",
    "***\n",
    "+ 로지스틱 회귀는 '선형 분류 모델'의 하나로 데이터 간의 관계를 토대로 분류 또는 확률을 계산하는 모델 입니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '모든 단어 사용(0.812)', '10,000개의 단어 사용(0.806)', '5,000개의 단어 사용(0.798)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-equipment",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _기존 나이브 베이즈 모델의 성능 보다 향상된 것을 확인할 수 있으며, 이는 CNB가 불균형한 데이터에 강건함을 잘 보여 줍니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "congressional-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.817\n",
      "F1-Score(Weight): 0.812\n",
      "F1-Score(Micro): 0.817\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.811\n",
      "F1-Score(Weight): 0.806\n",
      "F1-Score(Micro): 0.811\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.803\n",
      "F1-Score(Weight): 0.798\n",
      "F1-Score(Micro): 0.803\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    return LogisticRegression(C=10000, penalty='l2', max_iter=5000)\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-geometry",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "***\n",
    "+ 선형 서포트 벡터 머신은 초평면 상태에서 경게를 나누어 분류하는 모델 입니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '10,000개의 단어 사용(Micro: 0.786)', '모든 단어 사용(Micro: 0.785)', '5,000개 단어 사용(0.774)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-demonstration",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _SVM은 한 쪽으로 치우치지 않고 균등하게 분류 하고자 하는 특성이 있기 때문에, 나름 준수한 성능을 제시해 주는 것으로 보입니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intimate-flight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.785\n",
      "F1-Score(Weight): 0.781\n",
      "F1-Score(Micro): 0.785\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.786\n",
      "F1-Score(Weight): 0.781\n",
      "F1-Score(Micro): 0.786\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.776\n",
      "F1-Score(Weight): 0.774\n",
      "F1-Score(Micro): 0.776\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    return LinearSVC(C=1000, penalty='l1', max_iter=5000, dual=False)\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-barcelona",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 결정 트리(Decision Tree)\n",
    "***\n",
    "+ 결정 트리는 기준에 따라 분기와 노드를 생성함으로써 데이터를 분류하는 모델 입니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '10,000개의 단어 사용(0.578)', '모든 단어 사용(0.577)', '5,000개 단어 사용(0.573)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-statement",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _머신러닝 모델 중 가장 저조한 성능을 보여주었는데, 결정 트리의 단점 중 하나인 과적합 문제로 인해 불균형한 데이터를 올바르게 학습하지 못한 것으로 예상 됩니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nutritional-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.621\n",
      "F1-Score(Weight): 0.577\n",
      "F1-Score(Micro): 0.621\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.62\n",
      "F1-Score(Weight): 0.578\n",
      "F1-Score(Micro): 0.62\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.618\n",
      "F1-Score(Weight): 0.573\n",
      "F1-Score(Micro): 0.618\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    return DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-crawford",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 랜덤 포레스트(Random Forest)\n",
    "***\n",
    "+ 랜덤 포레스트는 결정 트리의 과적합 문제를 해결하고자 '랜덤 노드 최적화'와 '앙상블' 기법을 이용하였습니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '5,000개의 단어 사용(0.677)', '10,000개의 단어 사용(0.643)', '모든 단어 사용(0.623)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-shame",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _앞서 랜덤 포레스트는 결정 트리의 과적합 문제를 해결하기 위해 제시된 것이라 하였는데, 실제 결정 트리 모델의 성능 보다 향상 된 것을 확인할 수 있습니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "median-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.654\n",
      "F1-Score(Weight): 0.623\n",
      "F1-Score(Micro): 0.654\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.674\n",
      "F1-Score(Weight): 0.643\n",
      "F1-Score(Micro): 0.674\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.701\n",
      "F1-Score(Weight): 0.677\n",
      "F1-Score(Micro): 0.701\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    return RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-blanket",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 그래디언트 부스팅 트리(Gradient Boosting Classifier)\n",
    "***\n",
    "+ 그래디언트 부스팅 트리는 여러 개의 결정 트리를 이용하여 앙상블 기법을 사용하는 모델 입니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '5,000개의 단어 사용(0.749)', '모든 단어 사용(0.748)', '10,000개의 단어 사용(0.743)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-danger",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _LMS 본문에서는 그래디언트 부스팅 트리가 '랜덤 포레스트와 달리 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 생성한다'고 하였는데, 이러한 점으로 인해 랜덤 포르스트 보다 성능이 좋은 것이라 생각되어 집니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "polish-passport",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.762\n",
      "F1-Score(Weight): 0.748\n",
      "F1-Score(Micro): 0.762\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.757\n",
      "F1-Score(Weight): 0.743\n",
      "F1-Score(Micro): 0.757\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.762\n",
      "F1-Score(Weight): 0.749\n",
      "F1-Score(Micro): 0.762\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    return GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-basement",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 보팅(Voting)\n",
    "***\n",
    "+ 보팅은 여러 모델을 앙상블 기법으로 사용하는 모델로, 예제에서는 '로지스틱 회귀'와 'CNB'를 이용 합니다.\n",
    "\n",
    "\n",
    "+ `F1-Score`를 기준으로 '모든 단어 사용(0.810)', '10,000개의 단어 사용(0.0.805)', '5,000개의 단어 사용(0.803)' 순으로 성능이 좋은 것을 확인 하였습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-geography",
   "metadata": {},
   "source": [
    "##### 정성적 성능 해석\n",
    "+ _로지스틱 회귀와 성능이 비슷하지만, 5,000개의 단어만을 이용하였을 때, 기존 로지스틱 회귀의 성능 F1-Score(Weight)가 0.798에서 0.803으로 향상된 것을 바탕으로 좀 더 강건한 모델이라 생각되어 집니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "monetary-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********< All Vocab >*********\n",
      "Accuracy: 0.762\n",
      "F1-Score(Weight): 0.81\n",
      "F1-Score(Micro): 0.816\n",
      "******************************\n",
      "\n",
      "*******< 10,000 Vocab >*******\n",
      "Accuracy: 0.811\n",
      "F1-Score(Weight): 0.805\n",
      "F1-Score(Micro): 0.811\n",
      "******************************\n",
      "\n",
      "*******< 5,000 Vocab >********\n",
      "Accuracy: 0.809\n",
      "F1-Score(Weight): 0.803\n",
      "F1-Score(Micro): 0.809\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "            ('cb', ComplementNB())\n",
    "        ], voting='soft', n_jobs=-1\n",
    "    )\n",
    "    return voting_classifier\n",
    "\n",
    "\n",
    "cc, f1_w, f1_m = test_model(get_model(), tfidfv_train_all, y_train_all, tfidfv_test_all, y_test_all)\n",
    "print_model_result(acc, f1_w, f1_m, \"All Vocab\")\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_10th, y_train_10th, tfidfv_test_10th, y_test_10th)\n",
    "print_model_result(acc, f1_w, f1_m, \"10,000 Vocab\")\n",
    "\n",
    "\n",
    "acc, f1_w, f1_m = test_model(get_model(), tfidfv_train_5th, y_train_5th, tfidfv_test_5th, y_test_5th)\n",
    "print_model_result(acc, f1_w, f1_m, \"5,000 Vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-dublin",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. 딥러닝 모델 학습 및 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 1D Convolution 레이어를 사용한 딥러닝 모델을 사용 합니다. 동일한 로이터 뉴스 데이터셋을 이용하며, 단어 크기에 따른 성능을 확인 합니다. 모델의 학습 횟수 는 15회, 옵티마이저는 'Adam'으로 설정하여 학습 하였습니다. 그 결과, 모든 단어를 사용하여 모델을 학습 하였을 때, 테스트 데이터에 대한 최종 F1-Score는 0.781 이고 10,000개 단어를 사용하여 모델을 학습 하였을 때, 테스트 데이터에 대한 최종 F1-Score는 0.777, 5,000개 단어를 사용하여 모델을 학습 하였을 때, 테스트 데이터에 대한 최종 F1-Score는 0.783 입니다. [표 2]는 DNN 모델의 성능 평가 결과를 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "|Model|(all / 10,000 / 5,000) F1-Score(weight)|F1-Score(weight) Avg|\n",
    "|:--------:|:--------:|:--------:|\n",
    "|**DNN(1D Convolution)**|0.781 / 0.777 / 0.783|0.780|\n",
    "\n",
    "[표 2] DNN 모델 성능 평가 결과\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-blogger",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 데이터 전처리\n",
    "***\n",
    "+ 데이터 전처리(패딩 처리, 원-핫 인코딩, 검증 데이터 분할) 함수를 생성 합니다.\n",
    "\n",
    "\n",
    "+ '모든 단어', '10,000개 단어', '5,000개 단어' 데이터셋의 전처리를 수행 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chinese-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수=================================\n",
    "def get_dnn_data(x_train, y_train, x_test, y_test):\n",
    "    max_len=300\n",
    "\n",
    "    _x_train = pad_sequences(x_train, maxlen=max_len, padding=\"pre\")\n",
    "    _x_test = pad_sequences(x_test, maxlen=max_len, padding=\"pre\")\n",
    "\n",
    "    _y_train = to_categorical(y_train)\n",
    "    _y_test = to_categorical(y_test)\n",
    "\n",
    "    partial_x_train, x_val, partial_y_train, y_val = train_test_split(_x_train, _y_train, test_size=0.2, random_state=2021)\n",
    "    return (partial_x_train, partial_y_train, x_val, y_val, _x_test, _y_test)\n",
    "#End================================================\n",
    "\n",
    "\n",
    "dnn_data_all = get_dnn_data(\n",
    "    x_train_all, y_train_all, x_test_all, y_test_all\n",
    ")\n",
    "\n",
    "dnn_data_10th = get_dnn_data(\n",
    "    x_train_10th, y_train_10th, x_test_10th, y_test_10th\n",
    ")\n",
    "\n",
    "dnn_data_5th = get_dnn_data(\n",
    "    x_train_5th, y_train_5th, x_test_5th, y_test_5th\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-gather",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 생성 함수\n",
    "***\n",
    "+ 1D Convolution 레이어를 사용하는 모델을 생성 하고 옵티마이저는 'Adam'을 사용 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "municipal-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성 함수====================================\n",
    "def get_dnn(vocab_size):\n",
    "    word_vector_dim = 128\n",
    "\n",
    "    model_1d = tf.keras.Sequential()\n",
    "    model_1d.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model_1d.add(tf.keras.layers.Conv1D(256, 32, activation='relu'))\n",
    "    model_1d.add(tf.keras.layers.MaxPooling1D(4))\n",
    "    model_1d.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model_1d.add(tf.keras.layers.Conv1D(256, 32, activation='relu'))\n",
    "    model_1d.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "    model_1d.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model_1d.add(tf.keras.layers.Dense(46, activation='softmax'))\n",
    "    \n",
    "    model_1d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_m])\n",
    "    return model_1d\n",
    "#End================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-wisdom",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모델 학습 함수 생성\n",
    "***\n",
    "+ 모델을 학습하고 F1-Score를 출력하는 함수를 생성 합니다.\n",
    "\n",
    "\n",
    "+ 학습 횟수는 15회, 배치 사이즈는 64로 설정 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "otherwise-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1-Score 계산 함수=================================\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "#End================================================\n",
    "\n",
    "\n",
    "#모델 학습 함수====================================\n",
    "def train_model(model, data):\n",
    "    x_train, y_train, x_val, y_val = data[0], data[1], data[2], data[3]\n",
    "    x_test, y_test = data[4], data[5]\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=15, batch_size=64, verbose=1,\n",
    "        validation_data=(x_val, y_val)\n",
    "    )\n",
    "    \n",
    "    test_data = model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(\"< Test Performance >\".center(40, \"=\"))\n",
    "    print(\"Loss:\", round(test_data[0], 3))\n",
    "    print(\"Accuracy:\", round(test_data[1], 3))\n",
    "    print(\"F1-Score:\", round(test_data[2], 3))\n",
    "    print(\"=\" * 40)\n",
    "    return history\n",
    "#End================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-driver",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 모든 단어를 사용한 DNN 모델 학습 및 평가\n",
    "***\n",
    "+ 검증 데이터에 대한 최종 F1-score는 0.781, 테스트 데이터에 대한 최종 F1_score는 0.781 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finite-aviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "113/113 [==============================] - 17s 115ms/step - loss: 2.3291 - accuracy: 0.4243 - f1_m: 0.3614 - val_loss: 1.5181 - val_accuracy: 0.6227 - val_f1_m: 0.6685\n",
      "Epoch 2/15\n",
      "113/113 [==============================] - 9s 80ms/step - loss: 1.3089 - accuracy: 0.6652 - f1_m: 0.7130 - val_loss: 1.2103 - val_accuracy: 0.7106 - val_f1_m: 0.7420\n",
      "Epoch 3/15\n",
      "113/113 [==============================] - 9s 80ms/step - loss: 0.8770 - accuracy: 0.7752 - f1_m: 0.8205 - val_loss: 1.1561 - val_accuracy: 0.7474 - val_f1_m: 0.7469\n",
      "Epoch 4/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.6430 - accuracy: 0.8302 - f1_m: 0.8568 - val_loss: 1.1720 - val_accuracy: 0.7613 - val_f1_m: 0.7669\n",
      "Epoch 5/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.4736 - accuracy: 0.8730 - f1_m: 0.8896 - val_loss: 1.2663 - val_accuracy: 0.7685 - val_f1_m: 0.7690\n",
      "Epoch 6/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.3584 - accuracy: 0.9028 - f1_m: 0.9133 - val_loss: 1.2984 - val_accuracy: 0.7746 - val_f1_m: 0.7781\n",
      "Epoch 7/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.2420 - accuracy: 0.9362 - f1_m: 0.9343 - val_loss: 1.2753 - val_accuracy: 0.7780 - val_f1_m: 0.7738\n",
      "Epoch 8/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.1919 - accuracy: 0.9476 - f1_m: 0.9461 - val_loss: 1.3058 - val_accuracy: 0.7679 - val_f1_m: 0.7736\n",
      "Epoch 9/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.1853 - accuracy: 0.9485 - f1_m: 0.9517 - val_loss: 1.4756 - val_accuracy: 0.7780 - val_f1_m: 0.7802\n",
      "Epoch 10/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.1369 - accuracy: 0.9562 - f1_m: 0.9580 - val_loss: 1.5991 - val_accuracy: 0.7741 - val_f1_m: 0.7768\n",
      "Epoch 11/15\n",
      "113/113 [==============================] - 9s 80ms/step - loss: 0.1324 - accuracy: 0.9615 - f1_m: 0.9619 - val_loss: 1.4500 - val_accuracy: 0.7646 - val_f1_m: 0.7738\n",
      "Epoch 12/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.1219 - accuracy: 0.9595 - f1_m: 0.9623 - val_loss: 1.6751 - val_accuracy: 0.7796 - val_f1_m: 0.7797\n",
      "Epoch 13/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.1008 - accuracy: 0.9667 - f1_m: 0.9667 - val_loss: 1.6549 - val_accuracy: 0.7735 - val_f1_m: 0.7760\n",
      "Epoch 14/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.0838 - accuracy: 0.9694 - f1_m: 0.9698 - val_loss: 1.6676 - val_accuracy: 0.7802 - val_f1_m: 0.7804\n",
      "Epoch 15/15\n",
      "113/113 [==============================] - 9s 79ms/step - loss: 0.1008 - accuracy: 0.9643 - f1_m: 0.9647 - val_loss: 1.6935 - val_accuracy: 0.7668 - val_f1_m: 0.7660\n",
      "71/71 [==============================] - 3s 25ms/step - loss: 1.7464 - accuracy: 0.7774 - f1_m: 0.7811\n",
      "==========< Test Performance >==========\n",
      "Loss: 1.746\n",
      "Accuracy: 0.777\n",
      "F1-Score: 0.781\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf6567ad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_dnn(30982)\n",
    "train_model(model, dnn_data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-grace",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 10,000개 단어를 사용한 DNN 모델 학습 및 평가\n",
    "***\n",
    "+ 검증 데이터에 대한 최종 F1-score는 0.777, 테스트 데이터에 대한 최종 F1_score는 0.777 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "norwegian-amino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "113/113 [==============================] - 9s 71ms/step - loss: 2.3047 - accuracy: 0.4053 - f1_m: 0.3671 - val_loss: 1.4957 - val_accuracy: 0.6322 - val_f1_m: 0.6614\n",
      "Epoch 2/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 1.3451 - accuracy: 0.6651 - f1_m: 0.7113 - val_loss: 1.2765 - val_accuracy: 0.6939 - val_f1_m: 0.7400\n",
      "Epoch 3/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.9958 - accuracy: 0.7391 - f1_m: 0.7923 - val_loss: 1.1809 - val_accuracy: 0.7340 - val_f1_m: 0.7517\n",
      "Epoch 4/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.7000 - accuracy: 0.8173 - f1_m: 0.8478 - val_loss: 1.2394 - val_accuracy: 0.7529 - val_f1_m: 0.7587\n",
      "Epoch 5/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.5451 - accuracy: 0.8515 - f1_m: 0.8705 - val_loss: 1.2477 - val_accuracy: 0.7641 - val_f1_m: 0.7694\n",
      "Epoch 6/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.4099 - accuracy: 0.8810 - f1_m: 0.8923 - val_loss: 1.2419 - val_accuracy: 0.7646 - val_f1_m: 0.7675\n",
      "Epoch 7/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.3249 - accuracy: 0.9078 - f1_m: 0.9133 - val_loss: 1.2923 - val_accuracy: 0.7668 - val_f1_m: 0.7707\n",
      "Epoch 8/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.2619 - accuracy: 0.9249 - f1_m: 0.9277 - val_loss: 1.4184 - val_accuracy: 0.7674 - val_f1_m: 0.7688\n",
      "Epoch 9/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.2169 - accuracy: 0.9354 - f1_m: 0.9393 - val_loss: 1.5317 - val_accuracy: 0.7752 - val_f1_m: 0.7734\n",
      "Epoch 10/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.1549 - accuracy: 0.9573 - f1_m: 0.9553 - val_loss: 1.5372 - val_accuracy: 0.7607 - val_f1_m: 0.7634\n",
      "Epoch 11/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.1696 - accuracy: 0.9496 - f1_m: 0.9489 - val_loss: 1.6751 - val_accuracy: 0.7724 - val_f1_m: 0.7758\n",
      "Epoch 12/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.1383 - accuracy: 0.9580 - f1_m: 0.9590 - val_loss: 1.5872 - val_accuracy: 0.7791 - val_f1_m: 0.7776\n",
      "Epoch 13/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.1240 - accuracy: 0.9605 - f1_m: 0.9612 - val_loss: 1.6580 - val_accuracy: 0.7724 - val_f1_m: 0.7765\n",
      "Epoch 14/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.1170 - accuracy: 0.9586 - f1_m: 0.9621 - val_loss: 1.7055 - val_accuracy: 0.7774 - val_f1_m: 0.7762\n",
      "Epoch 15/15\n",
      "113/113 [==============================] - 8s 69ms/step - loss: 0.1013 - accuracy: 0.9662 - f1_m: 0.9664 - val_loss: 1.9471 - val_accuracy: 0.7730 - val_f1_m: 0.7711\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.9551 - accuracy: 0.7711 - f1_m: 0.7767\n",
      "==========< Test Performance >==========\n",
      "Loss: 1.955\n",
      "Accuracy: 0.771\n",
      "F1-Score: 0.777\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf63373d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_dnn(10000)\n",
    "train_model(model, dnn_data_10th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-cigarette",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 5,000개 단어를 사용한 DNN 모델 학습 및 평가\n",
    "***\n",
    "+ 검증 데이터에 대한 최종 F1-score는 0.783, 테스트 데이터에 대한 최종 F1_score는 0.783 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "owned-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "113/113 [==============================] - 9s 69ms/step - loss: 2.3066 - accuracy: 0.4312 - f1_m: 0.3525 - val_loss: 1.4971 - val_accuracy: 0.6199 - val_f1_m: 0.6661\n",
      "Epoch 2/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 1.3871 - accuracy: 0.6464 - f1_m: 0.6990 - val_loss: 1.2120 - val_accuracy: 0.7051 - val_f1_m: 0.7362\n",
      "Epoch 3/15\n",
      "113/113 [==============================] - 8s 66ms/step - loss: 1.0054 - accuracy: 0.7460 - f1_m: 0.7933 - val_loss: 1.1392 - val_accuracy: 0.7368 - val_f1_m: 0.7511\n",
      "Epoch 4/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.7313 - accuracy: 0.8086 - f1_m: 0.8372 - val_loss: 1.1387 - val_accuracy: 0.7618 - val_f1_m: 0.7600\n",
      "Epoch 5/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.5581 - accuracy: 0.8523 - f1_m: 0.8701 - val_loss: 1.1376 - val_accuracy: 0.7590 - val_f1_m: 0.7719\n",
      "Epoch 6/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.3937 - accuracy: 0.8905 - f1_m: 0.9035 - val_loss: 1.2179 - val_accuracy: 0.7663 - val_f1_m: 0.7694\n",
      "Epoch 7/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.3413 - accuracy: 0.9110 - f1_m: 0.9143 - val_loss: 1.3191 - val_accuracy: 0.7769 - val_f1_m: 0.7751\n",
      "Epoch 8/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.2715 - accuracy: 0.9267 - f1_m: 0.9305 - val_loss: 1.4109 - val_accuracy: 0.7696 - val_f1_m: 0.7728\n",
      "Epoch 9/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.2125 - accuracy: 0.9451 - f1_m: 0.9429 - val_loss: 1.3641 - val_accuracy: 0.7735 - val_f1_m: 0.7749\n",
      "Epoch 10/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.1900 - accuracy: 0.9480 - f1_m: 0.9483 - val_loss: 1.4612 - val_accuracy: 0.7785 - val_f1_m: 0.7797\n",
      "Epoch 11/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.1443 - accuracy: 0.9596 - f1_m: 0.9575 - val_loss: 1.5081 - val_accuracy: 0.7685 - val_f1_m: 0.7769\n",
      "Epoch 12/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.1575 - accuracy: 0.9536 - f1_m: 0.9543 - val_loss: 1.5934 - val_accuracy: 0.7741 - val_f1_m: 0.7787\n",
      "Epoch 13/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.1160 - accuracy: 0.9654 - f1_m: 0.9648 - val_loss: 1.5649 - val_accuracy: 0.7696 - val_f1_m: 0.7750\n",
      "Epoch 14/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.1166 - accuracy: 0.9621 - f1_m: 0.9649 - val_loss: 1.7345 - val_accuracy: 0.7780 - val_f1_m: 0.7792\n",
      "Epoch 15/15\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.0913 - accuracy: 0.9699 - f1_m: 0.9710 - val_loss: 1.6687 - val_accuracy: 0.7696 - val_f1_m: 0.7747\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.7522 - accuracy: 0.7787 - f1_m: 0.7828\n",
      "==========< Test Performance >==========\n",
      "Loss: 1.752\n",
      "Accuracy: 0.779\n",
      "F1-Score: 0.783\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf7284b90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_dnn(5000)\n",
    "train_model(model, dnn_data_5th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-transfer",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6. 결론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 본 예제에서는 고전적 머신러닝 모델과 딥러닝 모델의 성능 차이 그리고 단어사전 크기에 따른 모델의 성능 차이를 분석하기 위해, 로이터 뉴스 데이터셋을 이용하였습니다. 로이터 뉴스 데이터셋은 뉴스 본문과 본문에 해당하는 카테고리 값이 한 쌍으로 이루어졌으며, 특징으로는 카테고리 별 데이터 분포가 불균형 하다는 점 입니다. 따라서, 데이터의 불균형을 고려한 F1-Score를 평가지표로 사용 하였습니다. 최종적으로 데이터 크기에 따른 모델의 F1-Score의 평균을 모델의 성능 지표로 채택 하였습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 고전적 머신러닝 모델은 총 8개를 사용하였으며 딥러닝 모델로 1D Convolution 레이어를 이용한 모델을 채택하였습니다. 고전적 머신러닝 모델과 딥러닝 모델의 성능 차이를 확인한 결과, Voting(0.086), 로지스틱 회귀, 딥러닝, 선형 서포트 벡터 머신 등의 순으로 성능이 좋았습니다. 고전적 머신러닝 모델에 입력한 데이터의 경우 TF-IDF 임베딩을 사용하였지만, 딥러닝 모델에 입력한 데이터는 주어진 데이터를 별도의 전처리 없이 바로 사용 하였습니다. 이러한 점으로 인해 뚜렷한 성능의 향상을 도모하지 못한 것으로 짐작할 수 있습니다. [표 2]는 고전적 머신러닝과 딥러닝 모델의 성능을 제시한 것입니다.\n",
    "</span><br><br>\n",
    "    \n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 단어의 크기에 따른 성능 차이를 확인한 결과, 일관된 결과를 보여주지 않고 모델 별로 상이 하였습니다. 가령, Voting, 로지스틱 회귀 등의 모델의 경우 '모든 단어', '10,000개 단어', '5,000개 단어' 순으로 성능이 좋았지만, 딥러닝 모델, 랜덤 포레스트, 나이브 베이즈 등의 모델의 경우에는 '5,000개 단어', '10,000개 단어', '모든 단어' 순으로 좋았으며, '10,000개 단어'를 사용하였을 때 성능이 가장 준수한 모델도 존재하였습니다. 따라서, 모델을 학습 할 때, 단어의 크기는 '반드시 커야 한다' 혹은 '작아야 한다'와 같은 정답은 없으므로, 시행착오에 따른 설정이 필요할 것으로 예상 됩니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "|Rank|Model|(all / 10,000 / 5,000) F1-Score(weight)|F1-Score(weight) Avg|\n",
    "|:--------:|:--------:|:--------:|:--------:|\n",
    "|1|**Voting(Logistic Regression + CNB)**|0.810 / 0.805 / 0.803|0.806|\n",
    "|2|**Logistic Regression**|0.812 / 0.806 / 0.798|0.805|\n",
    "|3|**DNN(1D Convolution)**|0.781 / 0.777 / 0.783|0.780|\n",
    "|4|**Linear Support Vector Machine**|0.781 / 0.781 / 0.774|0.779|\n",
    "|5|**GBC**|0.748 / 0.743 / 0.749|0.747|\n",
    "|6|**CNB**|0.735 / 0.746 / 0.746|0.742|\n",
    "|7|**Random Forest**|0.623 / 0.643 / 0.677|0.648|\n",
    "|8|**Decision Tree**|0.577 / 0.578 / 0.573|0.576|\n",
    "|9|**Naive Bayes**|0.505 / 0.576 / 0.601|0.561|\n",
    "\n",
    "[표 3] 고전적 머신러닝 모델과 딥러닝 모델 성능\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-aaron",
   "metadata": {},
   "source": [
    "#### 형상관리 기록\n",
    "***\n",
    "+ v1_1: 실습 예제 진행\n",
    "\n",
    "\n",
    "+ v2_1: 제출 예제 진행\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
